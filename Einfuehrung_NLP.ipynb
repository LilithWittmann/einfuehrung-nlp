{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden werden anhand von Beispielen mithilfe der Software Libraries:\n",
    "- spacy - eine Toolsammlung um Probleme im Bereich NLP mithilfe von vortrainierten Deeplearning zu lösen\n",
    "- nltk - eher akademische Sammlung von Tools im Bereich NLP\n",
    "- TextBlob - abstraktion für einige spezifische deutsche Corpora (z.B. ready to use sentiment analysis…)\n",
    "\n",
    "einige elementare Methoden im Bereich NLP vorgestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "\n",
    "#load spacy de corpora\n",
    "nlp = spacy.load(\"de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieses Notebook dient als Ergänzung zu den Slides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"//lilith.slides.com/lilith/deck-31/embed?token=ivKQJ292\" width=\"576\" height=\"420\" scrolling=\"no\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML('<iframe src=\"//lilith.slides.com/lilith/deck-31/embed?token=ivKQJ292\" width=\"576\" height=\"420\" scrolling=\"no\" frameborder=\"0\" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für die meisten Tasks werden wir spacy benutzen, da es einerseits das aus meiner Sicht \"industry-grade\" tool für NLP und außerdem sehr einfach zu bedienen ist. In Spacy können wir das komplette lingustische preprocessing eines Satzes mit einem einzelnen Kommando erledigen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wie wird das Wetter morgen?"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"Wie wird das Wetter morgen?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit ```nlp(\"<text>\")``` durchläuft der Satz eine ganze Pipeline an funktionen und gibt den komplett annotierten Text als ein document zurück. Die Pipelines sehen dabei für jede Sprache etwas anders aus beinhalten grundsätzlich allerdings immer folgende Koponenten:\n",
    "- Tokenizer\n",
    "- POS-Tagging\n",
    "- Dependency Parsing\n",
    "- NER-Tagging\n",
    "\n",
    "Die Pipeline für Deutsch sieht so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x7f264a731908>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x7f264ace0c50>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x7f264a3a7150>)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline](https://spacy.io/assets/img/pipeline.svg)\n",
    "Im Folgenden werden wir uns mit den einzelnen Funktionen innerhalb dieser Pipeline beschäftigen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing\n",
    "\n",
    "Um Text sinnvoll weiterverarbeiten zu können, müssen wir ihn erst in seine einzelnen Bestandteile zerlegen. Das können einelne Wörter, Satzteile oder Sätze (Sentence Boundary Detection) sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wie', 'wird', 'das', 'Wetter', 'morgen', 'in', 'Hamburg', '?']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.WordPunctTokenizer().tokenize(\"Wie wird das Wetter morgen in Hamburg?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wie', 'wird', 'das', 'Wetter', 'morgen', 'in', 'Hamburg', '?']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in nlp(\"Wie wird das Wetter morgen in Hamburg?\")]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augenscheinlich machen sowohl der NLTK als auch der spacy tokenizer hier genau das selbe. Allerdings funktioniert der NLTK Tokenizer im Hintergrund quasi mit einem Regex, während spacy dafür erst den Satz selbst nach Spaces separiert und dann mit einzelnen Regeln je nach Sprache auch auf Edge-Cases wie Fremdwörter im Deutschen, die mit Bindestrich geschrieben werden, rücksicht nimmt. \n",
    "\n",
    "![caption](https://spacy.io/assets/img/tokenization.svg)\n",
    "\n",
    "Auch wenn das jetzt für Sprachen mit Lateinischen Alphabet erstmal relativ einfach aussieht, gibt es einige Sprachen (Chinesisch, Thailändisch, …) in denen das eine deutlich schwierigere Aufgabe ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Davon',\n",
       " 'hatte',\n",
       " 'Dr',\n",
       " '.',\n",
       " 'Müller',\n",
       " 'kein',\n",
       " 'Back',\n",
       " '-',\n",
       " 'up',\n",
       " 'gemacht',\n",
       " '!']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.WordPunctTokenizer().tokenize(\"Davon hatte Dr. Müller kein Back-up gemacht!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Davon', 'hatte', 'Dr.', 'Müller', 'kein', 'Back-up', 'gemacht', '!']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token.text for token in nlp(\"Davon hatte Dr. Müller kein Back-up gemacht!\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einen guten Tokenizer braucht man normalerweise nicht nur bei fast allen Anwendungsfällen im Bereich Natural Language Processing, sondern auch vielen weiteren Bereichen wie z.B. Suchsystemen. Außerdem sollte man bedenken, das fehler in diesem Bereich problematisch für alle weiteren Arbeitsschritte sein können.\n",
    "\n",
    "Beliebte weitere Fallstricke:\n",
    "- Abkürzungen wie Dr., Fr., … sollten als ein Token gesehen werden und nicht zu einer Satztrennung führen\n",
    "- Zahlen, Telefonnummern, feststehende Begriffe, … (je nach Level auf dem man tokenized vgl. High-Level-Tokenization)\n",
    "- Abkürzungen wie I'm, You're, …\n",
    "\n",
    "(https://www.ibm.com/developerworks/community/blogs/nlp/entry/tokenization?lang=en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech tagging (POS)\n",
    "\n",
    "Beim POS tagging geht es darum einen Satz in seine grammatikalischen Satzteile zu zerlegen. Es gibt dabei wieder unterschiedliche herangehensweisen wie das mithilfe von Software passieren kann. Spacy verwendet dabei statistische Verfahren (Markov Models). So ist die wahrscheinlichkeit relativ hoch das nach einem \"dem\" ein Substantiv im Dativ folgt. Diese Wahrscheinlichkeitskalkulationen passieren jetzt über mehrere Wörter hinweg, was dann zu einem relativ guten Ergebnis führt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"950\" height=\"137.0\" style=\"max-width: none; height: 137.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Der</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">Arzt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">NN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">hilft</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VVFIN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">dem</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Patienten</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"47.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">$.</tspan>\n",
       "</text>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Der Arzt hilft dem Patienten.')\n",
    "spacy_rendering = {\"words\": [], \"arcs\": []}\n",
    "for token in doc:\n",
    "    spacy_rendering[\"words\"].append({\"text\": token.text, \"tag\": token.tag_})\n",
    "HTML(displacy.render(spacy_rendering, style='dep', manual=True, options={\"compact\": True}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Für POS tagging alleine gibt es nicht so viele Usecases, allerdings ist es die Grundlage für Dependency Parsing und Named Entity Recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depedency Parsing\n",
    "Beim dependency parsing geht es darum, herauszufinden welches Wort sich wie auf welches andere Wort bezieht und hilft so auch dabei Haupt- und Nebensätze zu separieren um die Kernaussage eines Satzes herauszufinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"925\" height=\"312.0\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Der</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Arzt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">hilft</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">dem</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">Patienten.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">da</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Der Arzt hilft dem Patienten.')\n",
    "HTML(displacy.render(doc, style='dep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim NER geht es darum Informationen (insb. feststehende Begriffe) aus Texten zu extrahieren und zu klassifizieren. Dies passiert heute im Normalfall auf basis der annotierten Daten (POS; depedency tree) und "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Wie wird das Wetter morgen in \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hamburg\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       "?</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Wie wird das Wetter morgen in Hamburg?')\n",
    "HTML(displacy.render(doc, style='ent'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistische Methoden für NER ermöglichen uns auch für nicht im Trainingsset vorhandenen Namen/… Tags mit einer reltiv hohen Genauigkeit zu vergeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Wer ist \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Alan Turing\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       "?</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Wer ist Alan Turing?')\n",
    "HTML(displacy.render(doc, style='ent'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Wer ist \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Lilith Wittmann\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       "?</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('Wer ist Lilith Wittmann?')\n",
    "HTML(displacy.render(doc, style='ent'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bücher und andere Resourcen\n",
    "- [**spacy Doku** ](https://spacy.io/usage/spacy-101)\n",
    "- [nltk doku](https://www.nltk.org/)\n",
    "- [Next Generation Natural Language Processing with Python - Alexis Rutherford](https://www.safaribooksonline.com/library/view/natural-language-processing/9781787285101/)\n",
    "- [Natural Language Processing with Python Cookbook](https://www.safaribooksonline.com/library/view/natural-language-processing/9781787289321/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
